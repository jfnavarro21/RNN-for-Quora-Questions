{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "f765eb10-54e6-4a14-912b-e5117e8f433d"
    }
   },
   "source": [
    "# Advanced Machine Learning (MScA, 32017)\n",
    "\n",
    "# Project: Paraphrase Detection\n",
    "\n",
    "# Part 2: Solution by recurrent neural network\n",
    "\n",
    "### Yuri Balasanov, Leonid Nazarov, &copy; iLykei 2017\n",
    "\n",
    "Keras provides tools for Natural Language Processing including preprocessing text and working with pre-trained word embeddings. The goal of this notebook is to describe those tools and to give some basic examples of using them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools for Preprocessing Text\n",
    "\n",
    "\n",
    "## Text_to_word_sequence\n",
    "\n",
    "Function   \n",
    "\n",
    "*text_to_word_sequence(text, filters,lower=True,split=\" \")*  \n",
    "\n",
    "splits a sentence into a list of words. The arguments are\n",
    "\n",
    "- *text*: string.\n",
    "- *filters*: list (or concatenation) of characters to filter out, such as punctuation. Default: \n",
    "\n",
    "'!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\n' , includes basic punctuation, tabs, and newlines.\n",
    "\n",
    "- *lower*: boolean. Whether to set the text to lowercase.\n",
    "- *split*: string. Separator for word splitting.\n",
    "\n",
    "Apply it to Quora questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the step by step guide to invest in share market in india?\n",
      "['what', 'is', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in', 'share', 'market', 'in', 'india']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras.preprocessing.text import text_to_word_sequence, one_hot, Tokenizer \n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dataPath = \"./data/\"\n",
    "train = pd.read_csv(dataPath+'quora_train_1000.csv',usecols=['question1','question2'])\n",
    "train.dropna(inplace=True) # remove two rows as in NLP feature creation\n",
    "train = train[:1000] # only for demo and testing, comment out with complete data\n",
    "question = train.question1[0]\n",
    "print(question)\n",
    "print(text_to_word_sequence(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  \n",
       "0  What is the step by step guide to invest in sh...  \n",
       "1  What would happen if the Indian government sto...  \n",
       "2  How can Internet speed be increased by hacking...  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...  \n",
       "4            Which fish would survive in salt water?  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One_hot\n",
    "\n",
    "Function   \n",
    "\n",
    "*one_hot(text,n,filters,lower=True,split=\" \")*.    \n",
    "\n",
    "One-hot encodes a text into a list of numeric indices corresponding to words in a vocabulary of size n. <br>\n",
    "Returns list of integers in [1, n]. Each integer encodes a word (uniqueness non-guaranteed).  \n",
    "Integer *n* is vocabulary size, i.e. the number of different hash fields in the vocabulary. <br>\n",
    "Other parameters are the same as in *text_to_word_sequence*.\n",
    "\n",
    "In spite of the name it is **not one-hot**, the function actually implements [**hashing trick**](http://alex.smola.org/papers/2009/Weinbergeretal09.pdf) using *hash()* function. \n",
    "\n",
    "Hashing trick is named in association with kernel trick, but the way it works is in some sence opposite:\n",
    "\n",
    "- Kurnel trick expands dimensionality of the space in order to find a separating hyperplane;\n",
    "- Hashing trick reduces dimensionality by assigning a relatively small fixed number of hash labels to a multidimensional objects, like bag-of-words object.\n",
    "\n",
    "Here is an example.\n",
    "\n",
    "Apply one-hot to a simple sentence and see how hashing depends on the size of vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the step by step guide to invest in share market in india?\n",
      "[1, 1, 1]\n",
      "[1, 2, 2]\n",
      "[3, 2, 2]\n",
      "[3, 4, 4]\n",
      "[2, 4, 4]\n",
      "[3, 2, 2]\n",
      "[6, 6, 2]\n",
      "[7, 4, 8]\n"
     ]
    }
   ],
   "source": [
    "myText=text_to_word_sequence('I love data')\n",
    "print(question)\n",
    "for i in range(2,10,1):\n",
    "        print(one_hot('I love data',i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note **collisions**, i.e. same hashes assigned to different words. <br>\n",
    "Collisions reduce accuracy of classification, but not as much as it might seem: in [this article](http://hunch.net/~jl/projects/hash_reps/hash_kernels/hashkernel.pdf) authors described an experiment in which they observed collision rate of 94% (94% of features mapped to the same index as one or more other features) resulting in an increase in the experimental error rate from 5.5% to only 6%.\n",
    "\n",
    "Apply one-hot to the one of the questions. Use vocabulary of sizes 5 and 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the step by step guide to invest in share market in india?\n",
      "12 unique words\n",
      "[3, 3, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2] 3\n",
      "[608, 709, 933, 959, 241, 959, 134, 345, 956, 59, 902, 204, 59, 212] 12\n"
     ]
    }
   ],
   "source": [
    "print(question)\n",
    "print(len(set(text_to_word_sequence(question))),'unique words')\n",
    "print(one_hot(question,5),len(set(one_hot(question,5))))\n",
    "print(one_hot(question,1000),len(set(one_hot(question,1000))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note that with larger hash encoding is more likely unique.\n",
    "\n",
    "## Tokenizer\n",
    "\n",
    "Class  \n",
    "\n",
    "*Tokenizer(num_words=None,filters,lower=True,split=\" \",char_level=False)*  \n",
    "\n",
    "is designed for vectorizing texts, and/or turning texts into numeric sequences (=list of word indexes, where the word of rank i in the dataset (starting at 1) has index i).\n",
    "\n",
    "Arguments *filters, lower, split* are the same as in *text_to_word_sequence* above.\n",
    "\n",
    "- num_words: None or integer. Maximum number of words to work with (if set, tokenization will be restricted to the top num_words most common words in the dataset).\n",
    "- char_level: if True, every character will be treated as a token.  \n",
    "\n",
    "Method *fit_on_texts* takes the list of texts for training on as argument. <br>\n",
    "After *fit_on_texts* call class object has the following attrubutes:  \n",
    "\n",
    "- *word_counts*: dictionary mapping words (str) to their appearance number.\n",
    "- *word_docs*: dictionary mapping words (str) to the number of documents/texts in which they appeared.\n",
    "- *word_index*: dictionary mapping words (str) to their rank/index (int).\n",
    "- *document_count*: int. Number of documents (texts/sequences) the tokenizer was trained on.\n",
    "\n",
    " Apply *fit_on_texts* to the pair of questions and look at the  returned object attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I be a good geologist?\n",
      "What should I do to be a great geologist?\n",
      "word_index = {'i': 1, 'be': 2, 'a': 3, 'geologist': 4, 'how': 5, 'can': 6, 'good': 7, 'what': 8, 'should': 9, 'do': 10, 'to': 11, 'great': 12}\n",
      "word_counts = OrderedDict([('how', 1), ('can', 1), ('i', 2), ('be', 2), ('a', 2), ('good', 1), ('geologist', 2), ('what', 1), ('should', 1), ('do', 1), ('to', 1), ('great', 1)])\n",
      "word_docs = {'i': 2, 'can': 1, 'how': 1, 'geologist': 2, 'good': 1, 'a': 2, 'be': 2, 'should': 1, 'do': 1, 'great': 1, 'to': 1, 'what': 1}\n",
      "document_count = 2\n"
     ]
    }
   ],
   "source": [
    "texts = [train.question1[7],train.question2[7]]\n",
    "print(texts[0])\n",
    "print(texts[1])\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "for attr in ['word_index','word_counts','word_docs','document_count']:\n",
    "    print(attr, '=', vars(tokenizer)[attr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texts_to_sequences\n",
    "\n",
    "Method  \n",
    "\n",
    "*texts_to_sequences(texts)* \n",
    "\n",
    "transforms list of texts to list of sequences (one per text input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 6, 1, 2, 3, 7, 4], [8, 9, 1, 10, 11, 2, 3, 12, 4]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each word is replaced with its index in *word_index*.  \n",
    "\n",
    "Method \n",
    "\n",
    "*texts_to_matrix(texts)*  \n",
    "\n",
    "can be used to create one vector per document in *texts*.  <br>\n",
    "Length of vector is the total size of the vocabulary. <br>\n",
    "So, method returns numpy array of shape (len(texts), len(tokenizer.word_index)+1).\n",
    "\n",
    "In default \"binary\" mode the vector component equals 0 if there is no such word in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How can I be a good geologist?', 'What should I do to be a great geologist?']\n",
      "[[ 0.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  1.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(texts)\n",
    "print(tokenizer.texts_to_matrix(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modes \"count\", \"tfidf\" and \"freq\" are also available.\n",
    "\n",
    "Note that *texts_to_matrix* does not fit texts. It uses results of *fit_on_texts* call. In the example below we get zero vectors since selected questions have no words common with *texts* above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?', 'Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?']\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "texts1 = [train.question1[4],train.question1[4]]\n",
    "print(texts1)\n",
    "print(tokenizer.texts_to_matrix(texts1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding layer\n",
    "\n",
    "There is special layer in Keras designed to work with or without pre-trained embeddings or mappings of numbers from some vocabulary to vectors of real numbers:  \n",
    "\n",
    "*keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)*  \n",
    "\n",
    "This layer turns positive integers (usually word indexes in a dictionary) into dense vectors of fixed size. This layer can only be used as the first layer in a model. \n",
    "\n",
    "The list of arguments that will be used:\n",
    "\n",
    "- *input_dim*: int > 0. Size of the vocabulary, i.e. maximum size of dictionary.\n",
    "- *output_dim*: int >= 0. Dimension of the dense embedding.\n",
    "- *input_length*: Length of input sequences, when it is constant. This argument is required if you are going to connect Flatten then Dense layers upstream (without it, the shape of the dense outputs cannot be computed).  \n",
    "\n",
    "Below is the example of small sequential network with not pre-trained embedding layer. \n",
    "\n",
    "The largest integer (i.e. word index) in the input should not be larger than 999 (vocabulary size). \n",
    "\n",
    "Now model.output_shape == (None, 10, 64), where None is the batch dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"118pt\" viewBox=\"0.00 0.00 203.00 118.00\" width=\"203pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 114)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-114 199,-114 199,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 2494388446992 -->\n",
       "<g class=\"node\" id=\"node1\"><title>2494388446992</title>\n",
       "<polygon fill=\"none\" points=\"0,-73.5 0,-109.5 195,-109.5 195,-73.5 0,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97.5\" y=\"-87.8\">embedding_1_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 2494388446656 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2494388446656</title>\n",
       "<polygon fill=\"none\" points=\"16,-0.5 16,-36.5 179,-36.5 179,-0.5 16,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97.5\" y=\"-14.8\">embedding_1: Embedding</text>\n",
       "</g>\n",
       "<!-- 2494388446992&#45;&gt;2494388446656 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2494388446992-&gt;2494388446656</title>\n",
       "<path d=\"M97.5,-73.3129C97.5,-65.2895 97.5,-55.5475 97.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"101,-46.5288 97.5,-36.5288 94.0001,-46.5289 101,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "model = Sequential()\n",
    "# vocabulary of 7, giving vector of length 5, expect back matrix of 5x2\n",
    "model.add(Embedding(input_dim=7, output_dim=2, input_length=5))\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network consists of embedding layer. <br>\n",
    "\n",
    "It takes as input a numeric tensor of shape (None,input_length) and the first dimension of tensor shape is not specified ahead of time. <br>\n",
    "\n",
    "The output is a tensor with shape (None,input_length,output_dim) which is created by associating each number of the input with a vector of length *output_dim* based on the dictionary of length *input_dim* of vectors of length *output_dim*, i.e.dictionary has dimensions (input_dim,output_dim). <br>\n",
    "\n",
    "Dictionaly may be provided or not. Embedding layer may be trained or just use provided dictionary. <br>\n",
    "Trained weights have dimension (input_dim,output_dim).\n",
    "\n",
    "Print summary of the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 5, 2)              14        \n",
      "=================================================================\n",
      "Total params: 14\n",
      "Trainable params: 14\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "embeddingWeights=model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights in this example are not trained, but randomly selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.00404574,  0.04395901],\n",
       "        [-0.01903176,  0.00661968],\n",
       "        [-0.04307199, -0.03223918],\n",
       "        [-0.04035587,  0.03969958],\n",
       "        [ 0.02194336,  0.03976114],\n",
       "        [ 0.01879166,  0.00146125],\n",
       "        [ 0.04085871, -0.01919118]], dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddingWeights"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create random input vector and predict output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 2 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00404574,  0.04395901],\n",
       "        [ 0.00404574,  0.04395901],\n",
       "        [-0.01903176,  0.00661968],\n",
       "        [-0.04307199, -0.03223918],\n",
       "        [ 0.00404574,  0.04395901]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array = np.random.randint(5, size=(1, 5))\n",
    "print(input_array)\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "output_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how output array is created from the input and the matrix of weights: rows of output are arrays assigned to each element of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddingWeights=embeddingWeights[0]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights set to:\n",
      "[array([[ 1.00404572,  1.04395902],\n",
      "       [ 0.98096824,  1.00661969],\n",
      "       [ 0.95692801,  0.9677608 ],\n",
      "       [ 0.95964414,  1.03969955],\n",
      "       [ 1.02194333,  1.03976119],\n",
      "       [ 1.01879168,  1.00146127],\n",
      "       [ 1.04085875,  0.98080879]], dtype=float32)]\n",
      "Output is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 1.00404572,  1.04395902],\n",
       "        [ 1.00404572,  1.04395902],\n",
       "        [ 0.98096824,  1.00661969],\n",
       "        [ 0.95692801,  0.9677608 ],\n",
       "        [ 1.00404572,  1.04395902]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(input_dim=7,weights=[embeddingWeights], output_dim=2, input_length=5))\n",
    "SVG(model_to_dot(model1).create(prog='dot', format='svg'))\n",
    "model1.compile('rmsprop', 'mse')\n",
    "output_array = model1.predict(input_array)\n",
    "print('Weights set to:')\n",
    "print(model1.get_weights())\n",
    "print('Output is:')\n",
    "output_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Quora project embedding layer will take as input sequence of word indices in a vocabulary and return a vector of fixed length for each index according to a specially trained matrix.  \n",
    "\n",
    "## LTSM layer\n",
    "\n",
    "LSTM networks belong to a type of recurrent neural network capable of learning order dependence in sequence prediction problems. \n",
    "\n",
    "Here is an excellent post: [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/). \n",
    "\n",
    "### Regression example of LSTM model\n",
    "\n",
    "In this example create model with 1 LSTM layer to predict next value of a sequence of points taken from the curve shown on the following graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x244c5914470>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf0OBrQYec/+TAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x244bd811550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Activation, LSTM, Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adagrad, adam\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "\n",
    "\n",
    "N = 1000\n",
    "H = 2*np.pi/N\n",
    "t = H*np.arange(N)\n",
    "X = np.sin(t)*t\n",
    "\n",
    "plt.plot(t,X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "look_back = 6\n",
    "start = np.arange(N-look_back-1) # indexes of the sequence beginnig\n",
    "target = X[start+look_back]  # values to be predicted\n",
    "data = np.array([X[i:(i+look_back)] for i in start]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected LSTM input data shape is \n",
    "\n",
    "*(batch_size, timesteps, data_dim)*, \n",
    "\n",
    "where *timesteps* is the number of sequences in one sample. \n",
    "\n",
    "We have only 1 sequence in this example, so reshape input data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before (993, 6)\n",
      "after (993, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "print('before',data.shape)\n",
    "data = np.reshape(data, (data.shape[0], 1, look_back))\n",
    "print('after',data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras constuctor for [LSTM layer](https://keras.io/layers/recurrent/) has more than 20 arguments. \n",
    "\n",
    "For simplicity we list only fewcarguments recommended for this project:\n",
    " \n",
    "`keras.layers.LSTM(units, activation='tanh', recurrent_activation='hard_sigmoid', dropout=0.0, recurrent_dropout=0.0, ...)`\n",
    "\n",
    "- units: Positive integer, dimensionality of the output space.\n",
    "- activation: Activation function to use (see activations). If you pass None, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "- recurrent_activation: Activation function to use for the recurrent step (see activations).\n",
    "- dropout: Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.\n",
    "- recurrent_dropout: Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state.\n",
    "- ...: additional omitted parameters\n",
    "\n",
    "The following function creates simple LSTM network using functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LSTM_model(neurons):\n",
    "    # neurons: positive integer\n",
    "    input = Input(shape=(1, look_back))\n",
    "    x = LSTM(neurons)(input)\n",
    "    output = Dense(1, activation='linear')(x)\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "    return model\n",
    "\n",
    "model = LSTM_model(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the model by either *'SVG'* or *'plot_model'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"191pt\" viewBox=\"0.00 0.00 134.00 191.00\" width=\"134pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 187)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-187 130,-187 130,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 2494395783712 -->\n",
       "<g class=\"node\" id=\"node1\"><title>2494395783712</title>\n",
       "<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 126,-182.5 126,-146.5 0,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"63\" y=\"-160.8\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 2494395781752 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2494395781752</title>\n",
       "<polygon fill=\"none\" points=\"14,-73.5 14,-109.5 112,-109.5 112,-73.5 14,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"63\" y=\"-87.8\">lstm_1: LSTM</text>\n",
       "</g>\n",
       "<!-- 2494395783712&#45;&gt;2494395781752 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2494395783712-&gt;2494395781752</title>\n",
       "<path d=\"M63,-146.313C63,-138.289 63,-128.547 63,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"66.5001,-119.529 63,-109.529 59.5001,-119.529 66.5001,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2494395940312 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2494395940312</title>\n",
       "<polygon fill=\"none\" points=\"11,-0.5 11,-36.5 115,-36.5 115,-0.5 11,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"63\" y=\"-14.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 2494395781752&#45;&gt;2494395940312 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>2494395781752-&gt;2494395940312</title>\n",
       "<path d=\"M63,-73.3129C63,-65.2895 63,-55.5475 63,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"66.5001,-46.5288 63,-36.5288 59.5001,-46.5289 66.5001,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, to_file='LSTM_ex1.png',show_shapes=True,show_layer_names=True)\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting model from the saved file.\n",
    "![LSTM_ex1](./LSTM_ex1.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define *EarlyStopping* callback and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 794 samples, validate on 199 samples\n",
      "Epoch 1/100\n",
      "1s - loss: 3.8956 - val_loss: 8.3680\n",
      "Epoch 2/100\n",
      "0s - loss: 3.6381 - val_loss: 8.0416\n",
      "Epoch 3/100\n",
      "0s - loss: 3.4581 - val_loss: 7.7786\n",
      "Epoch 4/100\n",
      "0s - loss: 3.3105 - val_loss: 7.4804\n",
      "Epoch 5/100\n",
      "0s - loss: 3.1295 - val_loss: 7.0428\n",
      "Epoch 6/100\n",
      "0s - loss: 2.9268 - val_loss: 6.5683\n",
      "Epoch 7/100\n",
      "0s - loss: 2.7311 - val_loss: 6.1272\n",
      "Epoch 8/100\n",
      "0s - loss: 2.5537 - val_loss: 5.7575\n",
      "Epoch 9/100\n",
      "0s - loss: 2.4051 - val_loss: 5.4498\n",
      "Epoch 10/100\n",
      "0s - loss: 2.2840 - val_loss: 5.2004\n",
      "Epoch 11/100\n",
      "0s - loss: 2.1737 - val_loss: 4.9653\n",
      "Epoch 12/100\n",
      "0s - loss: 2.0684 - val_loss: 4.7414\n",
      "Epoch 13/100\n",
      "0s - loss: 1.9661 - val_loss: 4.5363\n",
      "Epoch 14/100\n",
      "0s - loss: 1.8705 - val_loss: 4.3342\n",
      "Epoch 15/100\n",
      "0s - loss: 1.7807 - val_loss: 4.1478\n",
      "Epoch 16/100\n",
      "0s - loss: 1.6998 - val_loss: 3.9624\n",
      "Epoch 17/100\n",
      "0s - loss: 1.6228 - val_loss: 3.7924\n",
      "Epoch 18/100\n",
      "0s - loss: 1.5524 - val_loss: 3.6234\n",
      "Epoch 19/100\n",
      "0s - loss: 1.4848 - val_loss: 3.4654\n",
      "Epoch 20/100\n",
      "0s - loss: 1.4207 - val_loss: 3.3141\n",
      "Epoch 21/100\n",
      "0s - loss: 1.3595 - val_loss: 3.1714\n",
      "Epoch 22/100\n",
      "0s - loss: 1.3016 - val_loss: 3.0267\n",
      "Epoch 23/100\n",
      "0s - loss: 1.2450 - val_loss: 2.8926\n",
      "Epoch 24/100\n",
      "0s - loss: 1.1917 - val_loss: 2.7622\n",
      "Epoch 25/100\n",
      "0s - loss: 1.1397 - val_loss: 2.6441\n",
      "Epoch 26/100\n",
      "0s - loss: 1.0920 - val_loss: 2.5219\n",
      "Epoch 27/100\n",
      "0s - loss: 1.0449 - val_loss: 2.4082\n",
      "Epoch 28/100\n",
      "0s - loss: 0.9996 - val_loss: 2.3023\n",
      "Epoch 29/100\n",
      "0s - loss: 0.9564 - val_loss: 2.2017\n",
      "Epoch 30/100\n",
      "0s - loss: 0.9154 - val_loss: 2.1034\n",
      "Epoch 31/100\n",
      "0s - loss: 0.8762 - val_loss: 2.0055\n",
      "Epoch 32/100\n",
      "0s - loss: 0.8376 - val_loss: 1.9166\n",
      "Epoch 33/100\n",
      "0s - loss: 0.8014 - val_loss: 1.8304\n",
      "Epoch 34/100\n",
      "0s - loss: 0.7665 - val_loss: 1.7472\n",
      "Epoch 35/100\n",
      "0s - loss: 0.7332 - val_loss: 1.6675\n",
      "Epoch 36/100\n",
      "0s - loss: 0.7008 - val_loss: 1.5952\n",
      "Epoch 37/100\n",
      "0s - loss: 0.6707 - val_loss: 1.5184\n",
      "Epoch 38/100\n",
      "0s - loss: 0.6406 - val_loss: 1.4521\n",
      "Epoch 39/100\n",
      "0s - loss: 0.6126 - val_loss: 1.3842\n",
      "Epoch 40/100\n",
      "0s - loss: 0.5856 - val_loss: 1.3207\n",
      "Epoch 41/100\n",
      "0s - loss: 0.5595 - val_loss: 1.2603\n",
      "Epoch 42/100\n",
      "0s - loss: 0.5352 - val_loss: 1.2006\n",
      "Epoch 43/100\n",
      "0s - loss: 0.5109 - val_loss: 1.1496\n",
      "Epoch 44/100\n",
      "0s - loss: 0.4885 - val_loss: 1.0933\n",
      "Epoch 45/100\n",
      "0s - loss: 0.4669 - val_loss: 1.0460\n",
      "Epoch 46/100\n",
      "0s - loss: 0.4463 - val_loss: 0.9922\n",
      "Epoch 47/100\n",
      "0s - loss: 0.4261 - val_loss: 0.9474\n",
      "Epoch 48/100\n",
      "0s - loss: 0.4068 - val_loss: 0.9038\n",
      "Epoch 49/100\n",
      "0s - loss: 0.3890 - val_loss: 0.8577\n",
      "Epoch 50/100\n",
      "0s - loss: 0.3712 - val_loss: 0.8193\n",
      "Epoch 51/100\n",
      "0s - loss: 0.3547 - val_loss: 0.7799\n",
      "Epoch 52/100\n",
      "0s - loss: 0.3387 - val_loss: 0.7431\n",
      "Epoch 53/100\n",
      "0s - loss: 0.3234 - val_loss: 0.7081\n",
      "Epoch 54/100\n",
      "0s - loss: 0.3088 - val_loss: 0.6736\n",
      "Epoch 55/100\n",
      "0s - loss: 0.2951 - val_loss: 0.6396\n",
      "Epoch 56/100\n",
      "0s - loss: 0.2815 - val_loss: 0.6133\n",
      "Epoch 57/100\n",
      "0s - loss: 0.2690 - val_loss: 0.5822\n",
      "Epoch 58/100\n",
      "0s - loss: 0.2568 - val_loss: 0.5514\n",
      "Epoch 59/100\n",
      "0s - loss: 0.2449 - val_loss: 0.5272\n",
      "Epoch 60/100\n",
      "0s - loss: 0.2338 - val_loss: 0.4988\n",
      "Epoch 61/100\n",
      "0s - loss: 0.2234 - val_loss: 0.4811\n",
      "Epoch 62/100\n",
      "0s - loss: 0.2132 - val_loss: 0.4580\n",
      "Epoch 63/100\n",
      "0s - loss: 0.2035 - val_loss: 0.4352\n",
      "Epoch 64/100\n",
      "0s - loss: 0.1943 - val_loss: 0.4114\n",
      "Epoch 65/100\n",
      "0s - loss: 0.1854 - val_loss: 0.3932\n",
      "Epoch 66/100\n",
      "0s - loss: 0.1769 - val_loss: 0.3734\n",
      "Epoch 67/100\n",
      "0s - loss: 0.1688 - val_loss: 0.3563\n",
      "Epoch 68/100\n",
      "0s - loss: 0.1613 - val_loss: 0.3438\n",
      "Epoch 69/100\n",
      "0s - loss: 0.1538 - val_loss: 0.3222\n",
      "Epoch 70/100\n",
      "0s - loss: 0.1468 - val_loss: 0.3055\n",
      "Epoch 71/100\n",
      "0s - loss: 0.1403 - val_loss: 0.2923\n",
      "Epoch 72/100\n",
      "0s - loss: 0.1336 - val_loss: 0.2792\n",
      "Epoch 73/100\n",
      "0s - loss: 0.1275 - val_loss: 0.2655\n",
      "Epoch 74/100\n",
      "0s - loss: 0.1218 - val_loss: 0.2528\n",
      "Epoch 75/100\n",
      "0s - loss: 0.1162 - val_loss: 0.2418\n",
      "Epoch 76/100\n",
      "0s - loss: 0.1109 - val_loss: 0.2296\n",
      "Epoch 77/100\n",
      "0s - loss: 0.1059 - val_loss: 0.2167\n",
      "Epoch 78/100\n",
      "0s - loss: 0.1009 - val_loss: 0.2114\n",
      "Epoch 79/100\n",
      "0s - loss: 0.0965 - val_loss: 0.2045\n",
      "Epoch 80/100\n",
      "0s - loss: 0.0920 - val_loss: 0.1962\n",
      "Epoch 81/100\n",
      "0s - loss: 0.0879 - val_loss: 0.1797\n",
      "Epoch 82/100\n",
      "0s - loss: 0.0839 - val_loss: 0.1703\n",
      "Epoch 83/100\n",
      "0s - loss: 0.0800 - val_loss: 0.1671\n",
      "Epoch 84/100\n",
      "0s - loss: 0.0764 - val_loss: 0.1563\n",
      "Epoch 85/100\n",
      "0s - loss: 0.0729 - val_loss: 0.1493\n",
      "Epoch 86/100\n",
      "0s - loss: 0.0696 - val_loss: 0.1515\n",
      "Epoch 87/100\n",
      "0s - loss: 0.0664 - val_loss: 0.1342\n",
      "Epoch 88/100\n",
      "0s - loss: 0.0634 - val_loss: 0.1378\n",
      "Epoch 89/100\n",
      "0s - loss: 0.0607 - val_loss: 0.1297\n",
      "Epoch 90/100\n",
      "0s - loss: 0.0578 - val_loss: 0.1223\n",
      "Epoch 91/100\n",
      "0s - loss: 0.0553 - val_loss: 0.1148\n",
      "Epoch 92/100\n",
      "0s - loss: 0.0530 - val_loss: 0.1145\n",
      "Epoch 93/100\n",
      "0s - loss: 0.0506 - val_loss: 0.1139\n",
      "Epoch 94/100\n",
      "0s - loss: 0.0485 - val_loss: 0.1034\n",
      "Epoch 95/100\n",
      "0s - loss: 0.0460 - val_loss: 0.1044\n",
      "Epoch 96/100\n",
      "0s - loss: 0.0441 - val_loss: 0.0949\n",
      "Epoch 97/100\n",
      "0s - loss: 0.0421 - val_loss: 0.0910\n",
      "Epoch 98/100\n",
      "0s - loss: 0.0402 - val_loss: 0.0870\n",
      "Epoch 99/100\n",
      "0s - loss: 0.0387 - val_loss: 0.0862\n",
      "Epoch 100/100\n",
      "0s - loss: 0.0368 - val_loss: 0.0772\n",
      "LSTM : loss =  0.0771745286376  epochs = 100\n"
     ]
    }
   ],
   "source": [
    "valid_size = 0.2 # splitting into train and test\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=1)\n",
    "\n",
    "hist = model.fit(data,target,epochs=100,validation_split = valid_size,\n",
    "          callbacks=[early_stopping],verbose=2)\n",
    "print('LSTM : loss = ',min(hist.history['val_loss']),' epochs =',\n",
    "      len(hist.history['val_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras does not shuffle the data in validation process. It just takes the end of the data for validation. <br>\n",
    "Make prediction of the part of the data that was not used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x244c55856a0>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x244c60706d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_dim = int(valid_size*data.shape[0])  # number of validation samples\n",
    "plt.plot(t,X)\n",
    "y = model.predict(data[-valid_dim:,:,:])\n",
    "plt.plot(t[-valid_dim:],y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to improve prediction quality increase number of neurons in LSTM layer to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM : loss =  0.0434727902856  epochs = 59\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x244d067fb70>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhJuRYhdCCDfz/wE09ChgB3Ny7QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x244cfe01780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LSTM_model(10)\n",
    "hist = model.fit(data,target,epochs=100,validation_split = valid_size,\n",
    "          callbacks=[early_stopping],verbose=0)\n",
    "print('LSTM : loss = ',min(hist.history['val_loss']),' epochs =',\n",
    "      len(hist.history['val_loss']))\n",
    "plt.plot(t,X)\n",
    "y = model.predict(data[-valid_dim:,:,:])\n",
    "plt.plot(t[-valid_dim:],y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With increased number of neurons RMSE is better. \n",
    "\n",
    "Increase number of neurons to 50 and check the results again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM : loss =  0.0728891554977  epochs = 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x244cd3d8780>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYRwMf8fWVxGrome+R4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x244ccb13940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LSTM_model(50)\n",
    "hist = model.fit(data,target,epochs=100,validation_split = valid_size,\n",
    "          callbacks=[early_stopping],verbose=0)\n",
    "print('LSTM : loss = ',min(hist.history['val_loss']),' epochs =',\n",
    "      len(hist.history['val_loss']))\n",
    "plt.plot(t,X)\n",
    "y = model.predict(data[-valid_dim:,:,:])\n",
    "plt.plot(t[-valid_dim:],y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More neurons does not always mean better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps of Preprocessing\n",
    "\n",
    "Description of all Keras tools necessary for converting questions into additional useful features for neural network is over. \n",
    "\n",
    "Now go through the several following steps of processing questions. \n",
    "\n",
    "## Step 1. Lemmatization\n",
    "\n",
    "Questions are preprocessed so that the different forms of writing the same text (like \"don't\" and \"do not\") are  matched. Lemmatization similar to one done in the first part of the project helps again. \n",
    "\n",
    "Lemmatize with *WordNetLemmatizer*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "WNL = WordNetLemmatizer()\n",
    "\n",
    "def cutter(word):\n",
    "    if len(word) < 4:\n",
    "        return word\n",
    "    return WNL.lemmatize(WNL.lemmatize(word, \"n\"), \"v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function *'cutter()'* lemmatizes words to standardized form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'visualize'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutter('visualizing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is one of preprocessing transformations of questions suggested during Kaggle competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess(string):\n",
    "    # standardize expression with apostrophe, replace some special symbols with word\n",
    "    string = string.lower().replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"\", \"'\").replace(\"\", \"'\") \\\n",
    "        .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\") \\\n",
    "        .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\") \\\n",
    "        .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\") \\\n",
    "        .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\") \\\n",
    "        .replace(\"%\", \" percent \").replace(\"\", \" rupee \").replace(\"$\", \" dollar \") \\\n",
    "        .replace(\"\", \" euro \").replace(\"'ll\", \" will\").replace(\"=\", \" equal \").replace(\"+\", \" plus \")\n",
    "    # remove punctuation and special symbols\n",
    "    string = re.sub('[\\(\\'\\)\\!\\^\\\"\\.;:,\\-\\?\\{\\}\\[\\]\\\\/\\*@]', ' ', string)\n",
    "    string = re.sub(r\"([0-9]+)000000\", r\"\\1m\", string)\n",
    "    string = re.sub(r\"([0-9]+)000\", r\"\\1k\", string)\n",
    "    # lemmatize\n",
    "    string = ' '.join([cutter(w) for w in string.split()])\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply preprocessing to train sample. \n",
    "\n",
    "All transformations applied to train should be applied to test too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: what is the story of kohinoor koh i noor diamond\n",
      "Question 2: what would happen if the indian government steal the kohinoor koh i noor diamond back\n",
      "Question 1 processed: what is the story of kohinoor koh i noor diamond\n",
      "Question 2 processed: what would happen if the indian government steal the kohinoor koh i noor diamond back\n"
     ]
    }
   ],
   "source": [
    "print('Question 1: %s' % train[\"question1\"][1])\n",
    "print('Question 2: %s' % train[\"question2\"][1])\n",
    "train[\"question1\"] = train[\"question1\"].fillna(\"\").apply(preprocess)\n",
    "train[\"question2\"] = train[\"question2\"].fillna(\"\").apply(preprocess)\n",
    "print('Question 1 processed: %s' % train.question1[1])\n",
    "print('Question 2 processed: %s' % train.question2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       what is the step by step guide to invest in sh...\n",
       "1        what is the story of kohinoor koh i noor diamond\n",
       "2       how can i increase the speed of my internet co...\n",
       "3        why am i mentally very lonely how can i solve it\n",
       "4       which one dissolve in water quikly sugar salt ...\n",
       "5       astrology i am a capricorn sun cap moon and ca...\n",
       "6                                      should i buy tiago\n",
       "7                           how can i be a good geologist\n",
       "8                          when do you use  instead of \n",
       "9       motorola company can i hack my charter motorol...\n",
       "10      method to find separation of slit use fresnel ...\n",
       "11              how do i read and find my youtube comment\n",
       "12                     what can make physic easy to learn\n",
       "13             what was your first sexual experience like\n",
       "14      what are the law to change your status from a ...\n",
       "15      what would a trump presidency mean for current...\n",
       "16                             what doe manipulation mean\n",
       "17      why do girl want to be friend with the guy the...\n",
       "18      why are so many quora user post question that ...\n",
       "19      which is the best digital market institution i...\n",
       "20                               why do rocket look white\n",
       "21                    what is cause someone to be jealous\n",
       "22          what are the question should not ask on quora\n",
       "23                                how much is 30 kv in hp\n",
       "24      what doe it mean that every time i look at the...\n",
       "25      what are some tip on make it through the job i...\n",
       "26                                what is web application\n",
       "27         doe society place too much importance on sport\n",
       "28                  what is best way to make money online\n",
       "29                  how should i prepare for ca final law\n",
       "                              ...                        \n",
       "1970    what was your biggest challenge as secretary o...\n",
       "1971       what exactly is a framework in layman own term\n",
       "1972                        doe okha express provide food\n",
       "1973                       where can i find a good hacker\n",
       "1974    how do i change the register mobile number for...\n",
       "1975    what are some tip on make it through the job i...\n",
       "1976    what are the main import and export of venezue...\n",
       "1977    how do the role of the cia the nsc and other r...\n",
       "1978                     what are the best movie to watch\n",
       "1979    can you download cydia on your device without ...\n",
       "1980              how do i get job in google or microsoft\n",
       "1981    fahrenheit 451 1953 book what is guy montag ow...\n",
       "1982    what is your review of love on the rock 2004 m...\n",
       "1983     is it possible to travel back or forward in time\n",
       "1984    why do we get sea breeze in summer but rarely ...\n",
       "1985             how do i recover delete facebook message\n",
       "1986       customer service what is uber own phone number\n",
       "1987    is there any way to purchase a phone on emi vi...\n",
       "1988                        what is agile and scrum model\n",
       "1989                        my life is bore what can i do\n",
       "1990                 where can i buy meldonium in the u s\n",
       "1991    what can be the most insane way to commit suicide\n",
       "1992                          is 100 76 ok blood pressure\n",
       "1993             what are your best paranormal experience\n",
       "1994    what exactly is the vyapam scam why have so ma...\n",
       "1995    my fiance die recently and it pain my heart h...\n",
       "1996    in sydney which company would be the best to g...\n",
       "1997    why most of the cosmetic product do not have p...\n",
       "1998    can we map the surface and the subsurface of a...\n",
       "1999                          dive the blue hole in dahab\n",
       "Length: 2000, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(train[\"question1\"].tolist() + train[\"question2\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Creating vocabulary of frequent words\n",
    "\n",
    "Create vocabulary of relatively frequent words in questions: words with frequency greater than *MIN_WORD_OCCURRENCE* times. \n",
    "\n",
    "For the small dataset *MIN_WORD_OCCURRENCE* is selected small, but for the whole dataset it should be much larger (may be in the range 50-150).\n",
    "\n",
    "For word count use familiar *CountVectorizer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019 top_words\n",
      "Top words ['try', 'relationship', 'love', 'got', 'youtube', 'screen', 'too', 'join', 'delete', 'hillary']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "MIN_WORD_OCCURRENCE = 3 # 3 for demo and testing in local environment. Select number for final results\n",
    "\n",
    "all_questions = pd.Series(train[\"question1\"].tolist() + train[\"question2\"].tolist()).unique()\n",
    "vectorizer = CountVectorizer(lowercase=False, token_pattern=\"\\S+\", # replace white spaces with spaces\n",
    "                             min_df=MIN_WORD_OCCURRENCE)\n",
    "vectorizer.fit(all_questions)\n",
    "top_words = set(vectorizer.vocabulary_.keys())\n",
    "print(len(top_words),'top_words')\n",
    "print('Top words %s' % list(top_words)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Remove rare words\n",
    "\n",
    "The consecutive rare words are replaced with one word \"suspense\" (you may try another replacement). The result is limited to 30 trailing words. \n",
    "\n",
    "Remove first words in long question since the end of it is usually more important. \n",
    "\n",
    "Add \"suspense\" to *top_words*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPLACE_WORD = \"suspense\"\n",
    "top_words.add(REPLACE_WORD)\n",
    "MAX_SEQUENCE_LENGTH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: motorola company can i hack my charter motorolla dcx3400\n",
      "Prepared question: suspense company can i hack my suspense\n"
     ]
    }
   ],
   "source": [
    "def prepare(q):\n",
    "    new_q = []\n",
    "    new_suspense = True # ready to add REPLACE_WORD \n",
    "    # a[::-1] invert order of list a, so we start from the end\n",
    "    for w in q.split()[::-1]:\n",
    "        if w in top_words:\n",
    "            new_q = [w] + new_q # add word from top_words\n",
    "            new_suspense = True\n",
    "        elif new_suspense:\n",
    "            new_q = [REPLACE_WORD] + new_q\n",
    "            new_suspense = False  # only 1 REPLACE_WORD for group of rare words\n",
    "        if len(new_q) == MAX_SEQUENCE_LENGTH:\n",
    "            break\n",
    "    new_q = \" \".join(new_q)\n",
    "    return new_q\n",
    "\n",
    "question = train.question1[9]\n",
    "print('Question: %s' % question)\n",
    "print('Prepared question: %s' % prepare(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function to train questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the step by step suspense to invest in share market in india\n"
     ]
    }
   ],
   "source": [
    "q1s_train = train.question1.apply(prepare)\n",
    "q2s_train = train.question2.apply(prepare)\n",
    "print(q1s_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Create embedding index\n",
    "\n",
    "Build embedding index - dictionary with words from *top_words* as keys and their vector presentations as values.\n",
    "\n",
    "Take vector presentations of words from Common Crawl (840B tokens, 2.2M vocab, cased, 300d vectors, 2.03 GB download) embedding file [glove.840B.300d](http://nlp.stanford.edu/data/glove.840B.300d.zip). Each line of the file contains word space separated from components of word vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "EMBEDDING_FILE = \"glove.840B.300d.txt\"\n",
    "\n",
    "def get_embedding():\n",
    "    embeddings_index = {}\n",
    "    with open(EMBEDDING_FILE, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            if len(values) == EMBEDDING_DIM + 1 and word in top_words:\n",
    "                coefs = np.asarray(values[1:], dtype=\"float32\")\n",
    "                embeddings_index[word] = coefs\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build *embeddings_index* and reduce *top_words* to those having vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words not found in the embedding: {'rohingya'}\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = get_embedding()\n",
    "print(\"Words not found in the embedding:\", top_words - embeddings_index.keys())\n",
    "top_words = embeddings_index.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Transform questions into integer valued sequences of equal lengths\n",
    "\n",
    "It is described above how *Tokenizer.texts_to_sequences* converts question to a list of integers. \n",
    "\n",
    "But such lists may have different lengths for different questions. \n",
    "\n",
    "Keras provides method for fixing this issue:\n",
    "\n",
    "*keras.preprocessing.sequence.pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.)* \n",
    "\n",
    "It transforms a list of *num_samples* sequences (lists of scalars) into a 2D Numpy array of shape \n",
    "\n",
    "*(num_samples, num_timesteps)*, \n",
    "\n",
    "where *num_timesteps* is either *maxlen* argument (if provided), or the length of the longest sequence.\n",
    "\n",
    "Sequences that are shorter than *num_timesteps* are padded with *value* at the end. Sequences longer than *num_timesteps* are truncated so that they have the desired length. \n",
    "\n",
    "Position where padding or truncation happens is determined by *padding* or *truncating*, respectively.\n",
    "\n",
    "Here are several examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sequences: [[1, 2], [1, 2, 3, 4, 5]]\n",
      "Padded default: [[0 0 0 1 2]\n",
      " [1 2 3 4 5]]\n",
      "Padded with maxlen=4: [[0 0 1 2]\n",
      " [2 3 4 5]]\n",
      "Padded with maxlen=4, padding=post: [[1 2 0 0]\n",
      " [2 3 4 5]]\n",
      "Padded with maxlen=4, padding=post, truncating=post: [[1 2 0 0]\n",
      " [1 2 3 4]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "sequences = [[1,2],[1,2,3,4,5]]\n",
    "print('Original sequences: %s' % sequences)\n",
    "print('Padded default: %s' % pad_sequences(sequences))\n",
    "print('Padded with maxlen=4: %s' % pad_sequences(sequences,maxlen=4))\n",
    "print('Padded with maxlen=4, padding=post: %s' % pad_sequences(sequences,maxlen=4,padding='post'))\n",
    "print('Padded with maxlen=4, padding=post, truncating=post: %s' \\\n",
    "      %pad_sequences(sequences,maxlen=4,padding='post',truncating='post'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit *Tokenizer* to the questions obtained after Step 3 and apply *texts_to_sequences* and *pad_sequences* to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final representation of first question 1:\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   4\n",
      "   2 301  72 301   1   7 302   9 219 220   9  40]\n",
      "Final representation of first question 2:\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   3   4   2 301  72 301   1   7 302   9 219 220]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(filters=\"\")\n",
    "tokenizer.fit_on_texts(np.append(q1s_train, q2s_train))\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "data_1 = pad_sequences(tokenizer.texts_to_sequences(q1s_train), \n",
    "                       maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data_2 = pad_sequences(tokenizer.texts_to_sequences(q2s_train), \n",
    "                       maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Final representation of first question 1:')\n",
    "print(data_1[0])\n",
    "print('Final representation of first question 2:')\n",
    "print(data_2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each question now is represented by a vector of 30 numbers.\n",
    "\n",
    "Repeat the same steps with *test* set and create:\n",
    "\n",
    "*q1s_test -> test_data_1*  \n",
    "*q2s_test -> test_data_2*  \n",
    "\n",
    "Do not refit Tokenizer, use the same as for *train*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(dataPath+'quora_test_1000.csv',usecols=['question1','question2'])\n",
    "test[\"question1\"] = test[\"question1\"].fillna(\"\").apply(preprocess)\n",
    "test[\"question2\"] = test[\"question2\"].fillna(\"\").apply(preprocess)\n",
    "q1s_test = test.question1.apply(prepare)\n",
    "q2s_test = test.question2.apply(prepare)\n",
    "test_data_1 = pad_sequences(tokenizer.texts_to_sequences(q1s_test), \n",
    "                       maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_data_2 = pad_sequences(tokenizer.texts_to_sequences(q2s_test), \n",
    "                       maxlen=MAX_SEQUENCE_LENGTH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Create embedding matrix\n",
    "\n",
    "Now make embedding matrix of weights from embedding index. \n",
    "\n",
    "The *i-th* row of this matrix is a vector representation of word with index *i* in *word_index*. \n",
    "\n",
    "The embedding matrix will be used as weights matrix for embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))  # matrix of zeros\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create embedding layer from embedding matrix as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(nb_words, EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting *trainable=False* declares that no changing weights is required during traning. \n",
    "\n",
    "This layer just transforms sequences of integers (word indexes) into sequences of their vector representations.  \n",
    "\n",
    "## Step 7. Save the data\n",
    "\n",
    "We prepared the the following variables for neural network:\n",
    "\n",
    "\n",
    "- *data_1*, *data_2*: padded numeric sequences for questions 1 and 2 in train sample \n",
    "- *test_data_1*, *test_data_2*: padded numeric sequences for questions 1 and 2 in test sample\n",
    "- *nb_words*: length of dictionary *'word_index'* \n",
    "- *embedding_matrix*: matrix for transformation in the embedding layer\n",
    "\n",
    "Save these variables to *.pkl* files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./savedData/data_1.pkl', 'wb') as f: pickle.dump(data_1, f, -1)\n",
    "with open('./savedData/data_2.pkl', 'wb') as f: pickle.dump(data_2, f, -1)\n",
    "with open('./savedData/nb_words.pkl', 'wb') as f: pickle.dump(nb_words, f, -1)\n",
    "with open('./savedData/embedding_matrix.pkl', 'wb') as f: pickle.dump(embedding_matrix, f, -1)\n",
    "with open('./savedData/test_data_1.pkl', 'wb') as f: pickle.dump(test_data_1, f, -1)\n",
    "with open('./savedData/test_data_2.pkl', 'wb') as f: pickle.dump(test_data_2, f, -1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network will also use NLP features obtained using Spark in the first part of the project.\n",
    "\n",
    "# Nework architecture\n",
    "\n",
    "Quora released a [public dataset of duplicate questions](https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs) before the  competition, so, some interesting solutions had been already available before it started. \n",
    "\n",
    "Among them were approaches from:\n",
    "\n",
    "- [Quora hackathon](https://engineering.quora.com/Semantic-Question-Matching-with-Deep-Learning), \n",
    "- [Deep learning model](https://github.com/bradleypallen/keras-quora-question-pairs)  by Bradley Pallen et al.\n",
    "\n",
    "Those approaches extensively use Recurrent Neural Networks usually with Long Short-Term Memory (LSTM) layers. \n",
    "\n",
    "The competition also showed the power of these methods. <br>\n",
    "\n",
    "Participant [aphex34](https://www.kaggle.com/aphex34) was the only solo competitor among top 10 teams. He used NN techniques on all stages of reasearch including feature engeneering (see [7-th solution overview](https://www.kaggle.com/c/quora-question-pairs/discussion/34697#192676)). But his code has not been published.  \n",
    "\n",
    "In order to solve the problem it is recommended to implement Ahmet Erdem's architecture which is relatively simple and also uses LSTM network.\n",
    "![Ahmed LSTM](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FLecture%207%20AdvML%2FAhmedAlgo.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network has 3 inputs: \n",
    "\n",
    "- input_1 and input_2 for questions converted to matrices (*data_1, data_2*) \n",
    "- and input_3 for NLP features. \n",
    "\n",
    "Questions share the same embedding_1 and lstm_1 layers. \n",
    "\n",
    "Denote *y1* and *y2* outputs of layer *'lstm_1'* corresponding to the first and the second inputs, respectively.\n",
    "\n",
    "Calculation inside red square is vector of squared differences of 2 outputs of layer *'lstm_1'*:\n",
    "\n",
    "1. Output *y1* is miltiplied by -1 in lambda_1 layer \n",
    "2. Then the result is added to *y2* in layer *'add_2'*. So, the output of layer *'add_2'* is difference between *y1* and *y2*. (Alternatively you can apply subtraction shown in Keras_basics.ipynb). \n",
    "3. The vector of differences is multiplied by itself element-wise in *'multiply_1'* layer. The result is vector of squared differences.\n",
    "\n",
    "Then the vector of squared differences is concatenated in layer *'concatenate_1'* with sum of *y1* and *y2* obtained in layer *'add_1'*.  \n",
    "\n",
    "The loss function to be minimized is *loss='binary_crossentropy'*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task description\n",
    "\n",
    "1. Prepare train and test data for network in local environment.\n",
    "2. Implement the network above and tune it in local environment with part of the train data. <br>\n",
    "    Parameters to be tuned are: number of neurons in each layer, dropout rates (including recurrent_dropout of LSTM layer), standard deviation of *GaussianNoise* layer, *batch_size*. \n",
    "3. Run the model on the cluster with complete data and generate submission file as follows:\n",
    "\n",
    "*submission = pd.DataFrame({\"test_id\": test_id, \"is_duplicate\": prediction_prob})*  \n",
    "*submission.to_csv(\"submission1.csv\", index=False)*,\n",
    "\n",
    "where *prediction_prob* is 1D array of prediction probabilities, *test_id* is index from *test_id* column of *test.csv* file.\n",
    "\n",
    "Example of sbatch file to run task on GPU is given below (do not forget to remove end of line symbols < br > at the end of each line):"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!/bin/bash <br>\n",
    "\n",
    "# This script will request one GPU device and 1 CPU core <br>\n",
    "\n",
    "#SBATCH --account=mscagpu <br>\n",
    "#SBATCH --job-name=Quora2 <br>\n",
    "#SBATCH --output=Quora2.out <br>\n",
    "#SBATCH --error=Quora2.err <br>\n",
    "#SBATCH --time=00:29:00 <br>\n",
    "#SBATCH --nodes=1 <br>\n",
    "#SBATCH --ntasks=1 <br>\n",
    "#SBATCH --partition=mscagpu <br>\n",
    "#SBATCH --gres=gpu:1 <br>\n",
    "#SBATCH --mem-per-cpu=12000 <br>\n",
    "\n",
    "\n",
    "# if your executable was built with CUDA, be sure to load the correct CUDA module: <br>\n",
    "module load Anaconda3 cuda/8.0 <br>\n",
    "\n",
    "# <br>\n",
    "# your GPU-based executable here <br>\n",
    "# <br>\n",
    "python ./model.py <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH=30\n",
    "# Network architecture\n",
    "def getModel(batchsize=512,embed_dim=300)\n",
    "    np.random.seed(1)\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(nb_words, EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getModel(dropout=0.1, neurons1=500, neurons2=250,optimizer=\"Adagrad\"):\n",
    "    np.random.seed(1)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons1, activation='relu', input_dim=num_features))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(neurons2, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign batch size as variable\n",
    "# lengths of vectrs we want to have\n",
    "# global variabeldimension max sequence length(30)\n",
    "# embedding layre needs embedding dimension ( 300)\n",
    "# bigger batch size, smoother gradient, accurate search, but uses memory\n",
    "\n",
    "#submission 1\n",
    "\n",
    "#is_dubplicate    test_id\n",
    "# select cutoff words"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
